{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import math\n",
    "import redis\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing.sharedctypes import RawArray\n",
    "from multiprocessing.shared_memory import SharedMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "os.chdir(Path(os.getcwd()).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.quotation import Quotation\n",
    "from libs.utils import Utils\n",
    "from libs.tdx import TDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyData:\n",
    "    \n",
    "    rd = redis.Redis(host='127.0.0.1', port=6379, db=8)\n",
    "    \n",
    "    basics_columns = ['zt_price', 'dt_price', 'ma5vpm', 'mcap', 'sum4', 'sum9', 'sum19', 'sum29', 'sum59']\n",
    "    snapshots_columns = ['open','close','now','high','low','turnover','volume', 'bid1', 'bid1_volume']\n",
    "    statistic_columns = ['zhangfu', 'junjia', 'liangbi', 'zhangsu', 'tingban', 'sum5', 'sum10', 'sum20', 'sum30', 'sum60']\n",
    "    \n",
    "    # date: %Y%m%d\n",
    "    def __init__(self, date=None, symbols=[], check_points=[], create=False):\n",
    "        \n",
    "        if date is None:\n",
    "            self.date = time.strftime('%Y%m%d')\n",
    "        else:\n",
    "            self.date = date\n",
    "            \n",
    "        self.hdf5_file = os.path.join(os.getcwd(), 'storage', f'{self.date}.hdf5')\n",
    "            \n",
    "        if create:\n",
    "            self.rd.set(f'hq_{self.date}_symbols_length', len(symbols))\n",
    "            self.rd.set(f'hq_{self.date}_check_points_length', len(check_points))\n",
    "            \n",
    "            self.shm_symbols = SharedMemory(name=f'${self.date}_symbols', create=True, size=len(symbols)*np.dtype('<U6').itemsize)\n",
    "            self.shm_names = SharedMemory(name=f'${self.date}_names', create=True, size=len(symbols)*np.dtype('<U4').itemsize)            \n",
    "            self.shm_check_points = SharedMemory(name=f'${self.date}_check_points', create=True, size=len(check_points)*np.dtype('<u4').itemsize)\n",
    "            self.shm_basics = SharedMemory(name=f'${self.date}_basics', create=True, size=len(check_points)*len(symbols)*len(self.basics_columns)*np.dtype('<f8').itemsize)\n",
    "            self.shm_snapshots = SharedMemory(name=f'${self.date}_snapshots', create=True, size=len(check_points)*len(symbols)*len(self.snapshots_columns)*np.dtype('<f8').itemsize)\n",
    "            self.shm_statistic = SharedMemory(name=f'${self.date}_statistic', create=True, size=len(check_points)*len(symbols)*len(self.statistic_columns)*np.dtype('<f8').itemsize)\n",
    "        \n",
    "            self.symbols = np.ndarray((len(symbols),), dtype='<U6', buffer=self.shm_symbols.buf)\n",
    "            self.names = np.ndarray((len(symbols),), dtype='<U4', buffer=self.shm_names.buf)\n",
    "            self.check_points = np.ndarray(\n",
    "                (len(check_points),), \n",
    "                dtype='<u4', \n",
    "                buffer=self.shm_check_points.buf\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            self.shm_symbols = SharedMemory(name=f'${self.date}_symbols')\n",
    "            self.shm_names = SharedMemory(name=f'${self.date}_names')\n",
    "            self.shm_check_points = SharedMemory(name=f'${self.date}_check_points')\n",
    "            self.shm_basics = SharedMemory(name=f'${self.date}_basics')\n",
    "            self.shm_snapshots = SharedMemory(name=f'${self.date}_snapshots')\n",
    "            self.shm_statistic = SharedMemory(name=f'${self.date}_statistic')\n",
    "            \n",
    "            symbols_length = int(self.rd.get(f'hq_{self.date}_symbols_length'))\n",
    "            check_points_length = int(self.rd.get(f'hq_{self.date}_check_points_length'))\n",
    "            \n",
    "            self.symbols = np.ndarray((symbols_length,), dtype='<U6', buffer=self.shm_symbols.buf)\n",
    "            self.names = np.ndarray((symbols_length,), dtype='<U4', buffer=self.shm_names.buf)\n",
    "            self.check_points = np.ndarray(\n",
    "                (check_points_length,), \n",
    "                dtype='<u4', \n",
    "                buffer=self.shm_check_points.buf\n",
    "            )\n",
    "            \n",
    "            self.post_init()\n",
    "        \n",
    "        self.basics = np.ndarray(\n",
    "            (len(self.symbols), len(self.basics_columns)), \n",
    "            dtype='<f8', \n",
    "            buffer=self.shm_basics.buf\n",
    "        )\n",
    "        self.snapshots = np.ndarray(\n",
    "            (len(self.check_points), len(self.symbols), len(self.snapshots_columns)), \n",
    "            dtype='<f8', \n",
    "            buffer=self.shm_snapshots.buf\n",
    "        )\n",
    "        self.statistic = np.ndarray(\n",
    "            (len(self.check_points), len(self.symbols), len(self.statistic_columns)), \n",
    "            dtype='<f8', \n",
    "            buffer=self.shm_statistic.buf\n",
    "        )\n",
    "        \n",
    "    \n",
    "    async def prepare(self, symbols, check_points):\n",
    "        q = Quotation(symbols)\n",
    "        snapshot = await q.snapshot()\n",
    "\n",
    "        self.symbols[:] = symbols[:]\n",
    "        self.names[:] = [ snapshot[symbol]['name'] for symbol in symbols ][:]\n",
    "        self.check_points[:] = check_points[:]\n",
    "\n",
    "        self.basics.fill(np.nan)\n",
    "        self.snapshots.fill(np.nan)\n",
    "        self.statistic.fill(np.nan)\n",
    "\n",
    "        market_values = await q.get_market_values()\n",
    "\n",
    "        await q.exit()\n",
    "        \n",
    "        tdx = TDX()\n",
    "        assert tdx.is_local_tdx_data_outdated() is not True\n",
    "        klines = tdx.kline(symbols)\n",
    "\n",
    "        for _, symbol in enumerate(symbols):\n",
    "            self.basics[_, 0] = market_values[symbol]['zt_price']\n",
    "            self.basics[_, 1] = market_values[symbol]['dt_price']\n",
    "            self.basics[_, 3] = market_values[symbol]['mcap']\n",
    "\n",
    "            if symbol not in klines:\n",
    "                continue\n",
    "                \n",
    "            kline = klines[symbol]\n",
    "            self.basics[_, 2] = kline.iloc[0-min(5,len(kline)):]['volume'].sum()/1200\n",
    "            self.basics[_, 4] = kline.iloc[-4:]['close'].sum() if len(kline) >= 4 else np.nan\n",
    "            self.basics[_, 5] = kline.iloc[-9:]['close'].sum() if len(kline) >= 9 else np.nan\n",
    "            self.basics[_, 6] = kline.iloc[-19:]['close'].sum() if len(kline) >= 19 else np.nan\n",
    "            self.basics[_, 7] = kline.iloc[-29:]['close'].sum() if len(kline) >= 29 else np.nan\n",
    "            self.basics[_, 8] = kline.iloc[-59:]['close'].sum() if len(kline) >= 59 else np.nan\n",
    "            \n",
    "#         await q.exit()\n",
    "        self.post_init()\n",
    "            \n",
    "            \n",
    "    def post_init(self):\n",
    "        self.check_interval = self.check_points[2] - self.check_points[1]\n",
    "        start_time_0_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 09:15:00'\n",
    "        start_time_1_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 09:30:00'\n",
    "        start_time_2_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 13:00:00'\n",
    "        end_time_0_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 09:25:00'\n",
    "        end_time_1_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 11:30:00'\n",
    "        end_time_2_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 15:00:00'\n",
    "        start_time_0 = int(time.mktime(time.strptime(start_time_0_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        start_time_1 = int(time.mktime(time.strptime(start_time_1_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        start_time_2 = int(time.mktime(time.strptime(start_time_2_str, '%Y-%m-%d %H:%M:%S')))   \n",
    "        end_time_0 = int(time.mktime(time.strptime(end_time_0_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        end_time_1 = int(time.mktime(time.strptime(end_time_1_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        end_time_2 = int(time.mktime(time.strptime(end_time_2_str, '%Y-%m-%d %H:%M:%S')))   \n",
    "        \n",
    "        start_time_idx_0 = np.where(self.check_points == start_time_0)[0][0]\n",
    "        start_time_idx_1 = np.where(self.check_points == start_time_1)[0][0]\n",
    "        start_time_idx_2 = np.where(self.check_points == start_time_2)[0][0]\n",
    "        end_time_idx_0 = np.where(self.check_points == end_time_0)[0][0]\n",
    "        end_time_idx_1 = np.where(self.check_points == end_time_1)[0][0]\n",
    "        end_time_idx_2 = np.where(self.check_points == end_time_2)[0][0]\n",
    "        self.active_time_blocks = [\n",
    "            ((start_time_idx_0, start_time_0, start_time_0_str),(end_time_idx_0, end_time_0, end_time_0_str)),\n",
    "            ((start_time_idx_1, start_time_1, start_time_1_str),(end_time_idx_1, end_time_1, end_time_1_str)),\n",
    "            ((start_time_idx_2, start_time_2, start_time_2_str),(end_time_idx_2, end_time_2, end_time_2_str))\n",
    "        ]\n",
    "        self.rd.set(f'{self.date}_data_ready', 'true')\n",
    "        \n",
    "    \n",
    "    def get_securities(self):\n",
    "        return pd.DataFrame({\n",
    "            \"symbol\": self.symbols,\n",
    "            \"name\": self.names,\n",
    "            \"zt_price\": self.basics[:,0],\n",
    "            \"dt_price\": self.basics[:,1],\n",
    "            \"ma5vpm\": self.basics[:,2],\n",
    "            \"mcap\": self.basics[:,3],\n",
    "            \"sum4\": self.basics[:,4],\n",
    "            \"sum9\": self.basics[:,5],\n",
    "            \"sum19\": self.basics[:,6],\n",
    "            \"sum29\": self.basics[:,7],\n",
    "            \"sum59\": self.basics[:,8]\n",
    "        }).set_index('symbol')\n",
    "    \n",
    "    \n",
    "    # check_point: timestamp or %H:%M:%S\n",
    "    def get_snapshot(self, check_point):\n",
    "        if type(check_point) == int and check_point <= 100000:\n",
    "            index = check_point\n",
    "        elif type(check_point) == float or type(check_point) == int:\n",
    "            index = np.where(self.check_points == check_point)[0][0]\n",
    "        elif type(check_point) == str:\n",
    "            index = [ time.strftime('%H:%M:%S', time.localtime(cp)) for cp in self.check_points ].index(check_point)\n",
    "            \n",
    "            \n",
    "        return pd.DataFrame({\n",
    "            \"datetime\": [ check_point if type(check_point) == str else time.strftime('%H:%M:%S', time.localtime(check_point)) for _ in range(len(self.symbols)) ], \n",
    "            \"timestamp\": [ self.check_points[index] if type(check_point) == str else check_point for _ in range(len(self.symbols)) ],\n",
    "            \"symbol\": self.symbols,\n",
    "            \"name\": self.names,\n",
    "            \"open\": self.snapshots[index,:,0],\n",
    "            \"close\": self.snapshots[index,:,1],\n",
    "            \"now\": self.snapshots[index,:,2],\n",
    "            \"high\": self.snapshots[index,:,3],\n",
    "            \"low\": self.snapshots[index,:,4],\n",
    "            \"turnover\": self.snapshots[index,:,5],\n",
    "            \"volume\": self.snapshots[index,:,6],\n",
    "            \"bid1\": self.snapshots[index,:,7],\n",
    "            \"bid1_volume\": self.snapshots[index,:,8],\n",
    "            \"zhangfu\": self.statistic[index,:,0],\n",
    "            \"junjia\": self.statistic[index,:,1],\n",
    "            \"liangbi\": self.statistic[index,:,2],\n",
    "            \"zhangsu\": self.statistic[index,:,3],\n",
    "            \"tingban\": self.statistic[index,:,4],\n",
    "            \"ma5\": self.statistic[index,:,5]\n",
    "        }).set_index('symbol')\n",
    "    \n",
    "    # dt: %Y%m%d\n",
    "    def save(self, gzip_level=4):\n",
    "        folder = os.path.join(os.getcwd(), 'storage')\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "#         file = os.path.join(folder, f'{self.date}.hdf5')\n",
    "        \n",
    "        if os.path.exists(self.hdf5_file):\n",
    "            print('文件 [', self.hdf5_file, '] 已经存在，将被删除 ... ... ', end='')\n",
    "            os.remove(self.hdf5_file)\n",
    "            print('已被删除')\n",
    "            \n",
    "        symbols = np.char.encode(self.symbols, encoding='utf-8')\n",
    "        names = np.char.encode(self.names, encoding='utf-8')\n",
    "        with h5py.File(self.hdf5_file, \"a\") as f:\n",
    "            f.create_dataset(u\"symbols\", data=symbols, compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"names\", data=names, compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"check_points\", data=self.check_points, compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"basics\", data=self.basics, compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"snapshots\", data=self.snapshots, compression=\"gzip\", compression_opts=gzip_level)\n",
    "#             f.create_dataset(u\"statistic\", data=self.statistic, compression=\"gzip\", compression_opts=gzip_level)\n",
    "            \n",
    "        print('行情 已经 写入文件：', self.hdf5_file)\n",
    "            \n",
    "    # dt: %Y%m%d\n",
    "    @staticmethod\n",
    "    def load(dt=None):\n",
    "        date = time.strftime(\"%Y%m%d\", time.localtime()) if dt is None else dt\n",
    "        file = os.path.join(os.getcwd(), 'storage', f'{date}.hdf5')\n",
    "        assert os.path.exists(file), 'file['+file+'] does not exists!'\n",
    "        \n",
    "        with h5py.File(file, \"a\") as f:\n",
    "            symbols = np.char.decode(f[u'symbols'], 'utf-8')\n",
    "            check_points = f[u'check_points'][:]\n",
    "            \n",
    "            data = DailyData(date=date, symbols=symbols, check_points=check_points, create=True)\n",
    "            data.symbols[:] = symbols[:]\n",
    "            data.names[:] = np.char.decode(f[u'names'], 'utf-8')\n",
    "            data.check_points[:] = check_points\n",
    "            data.basics[:,:] = f[u'basics'][:,:]\n",
    "            data.snapshots[:,:,:] = f[u'snapshots'][:,:,:]\n",
    "#             data.statistic[:,:,:] = f[u'statistic'][:,:,:]\n",
    "            \n",
    "        data.post_init()\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def get_ma5pm_anchor_idx(self, idx):\n",
    "#         st = time.time()\n",
    "\n",
    "        ck = self.check_points[idx]\n",
    "\n",
    "        if ck <= self.active_time_blocks[0][0][1]+300:\n",
    "            ma5pm_anchor_idx = self.active_time_blocks[0][0][0] - 1\n",
    "\n",
    "        elif self.active_time_blocks[0][1][1] < ck < self.active_time_blocks[1][0][1]:\n",
    "            ma5pm_anchor_idx = int(self.active_time_blocks[0][1][0] - 300/self.check_interval)\n",
    "\n",
    "        elif self.active_time_blocks[1][0][1] <= ck <= self.active_time_blocks[1][0][1]+300:\n",
    "            ma5pm_anchor_idx = self.active_time_blocks[1][0][0] - 1\n",
    "\n",
    "        elif self.active_time_blocks[1][1][1] < ck < self.active_time_blocks[2][0][1]:\n",
    "            ma5pm_anchor_idx = int(self.active_time_blocks[1][1][0] - 300/self.check_interval)\n",
    "\n",
    "        elif self.active_time_blocks[2][0][1] <= ck <= self.active_time_blocks[2][0][1]+300:\n",
    "            result = math.ceil(self.check_points[idx]/60)*60-300\n",
    "            offset = int((result-self.check_points[idx])/self.check_interval)\n",
    "\n",
    "            ma5pm_anchor_idx = int(max(idx+offset-2, self.active_time_blocks[1][1][0] - 240/self.check_interval))\n",
    "\n",
    "            if ma5pm_anchor_idx == self.active_time_blocks[1][1][0]:\n",
    "                ma5pm_anchor_idx += 1\n",
    "\n",
    "        elif self.active_time_blocks[2][1][1] < ck:\n",
    "            ma5pm_anchor_idx = int(self.active_time_blocks[2][1][0]-300/self.check_interval)\n",
    "\n",
    "        else:\n",
    "            result = math.ceil(self.check_points[idx]/60)*60-300\n",
    "            offset = int((result-self.check_points[idx])/self.check_interval)\n",
    "\n",
    "            ma5pm_anchor_idx = idx+offset\n",
    "\n",
    "#         et = time.time()\n",
    "\n",
    "#         print(\n",
    "#             idx, ' : ', ma5pm_anchor_idx, '       ', \n",
    "#             time.strftime(\"%H:%M:%S\", time.localtime(self.check_points[idx])),\n",
    "#             ' ==> ',\n",
    "#             time.strftime(\"%H:%M:%S\", time.localtime(self.check_points[ma5pm_anchor_idx])), '       ',\n",
    "#             ck, ' : ', self.check_points[ma5pm_anchor_idx], '       ',\n",
    "#             et-st\n",
    "#         )\n",
    "\n",
    "        return ma5pm_anchor_idx\n",
    "\n",
    "\n",
    "    def get_time_lapse(self, idx):\n",
    "    \n",
    "        ck = self.check_points[idx]\n",
    "        offset = 0\n",
    "        if ck < self.active_time_blocks[1][0][1]:\n",
    "            start_time = self.active_time_blocks[0][0][1]\n",
    "            if ck > self.active_time_blocks[0][1][1]:\n",
    "                ck = self.active_time_blocks[0][1][1]\n",
    "        elif ck < self.active_time_blocks[2][0][1]:\n",
    "            start_time = self.active_time_blocks[1][0][1]\n",
    "            if ck > self.active_time_blocks[1][1][1]:\n",
    "                ck = self.active_time_blocks[1][1][1]\n",
    "        else:\n",
    "            start_time = self.active_time_blocks[2][0][1]\n",
    "            if ck > self.active_time_blocks[2][1][1]:\n",
    "                ck = self.active_time_blocks[2][1][1]\n",
    "            offset = 120\n",
    "\n",
    "        return max(int(math.ceil((ck - start_time)/60)),1)+offset\n",
    "    \n",
    "    \n",
    "    def close_sharedmemory(self):\n",
    "        self.shm_symbols.close()\n",
    "        self.shm_names.close()\n",
    "        self.shm_check_points.close()\n",
    "        self.shm_basics.close()\n",
    "        self.shm_snapshots.close()\n",
    "        self.shm_statistic.close()\n",
    "        \n",
    "        \n",
    "    def unlink_sharedmemory(self):\n",
    "        self.shm_symbols.unlink()\n",
    "        self.shm_names.unlink()\n",
    "        self.shm_check_points.unlink()\n",
    "        self.shm_basics.unlink()\n",
    "        self.shm_snapshots.unlink()\n",
    "        self.shm_statistic.unlink()\n",
    "        \n",
    "        \n",
    "    def incremental_save(self, idx):\n",
    "        if not hasattr(self, 'hdf5'):\n",
    "            if not os.path.exists(self.hdf5_file):\n",
    "                return 'file['+self.hdf5_file+'] does not exists!'\n",
    "            self.hdf5 = h5py.File(self.hdf5_file, 'r+')\n",
    "            \n",
    "        self.hdf5[u'snapshots'][idx] = self.snapshots[idx]\n",
    "        self.hdf5.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items=[234,233,234,234,235]\n",
    "all(items[0] == item for item in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await asyncio.sleep(int(time.mktime(time.strptime(f'{time.strftime(\"%Y-%m-%d\")} 09:10:30', '%Y-%m-%d %H:%M:%S'))) - time.time()) \n",
    "\n",
    "Utils.update_symbols()\n",
    "\n",
    "snapshot_interval = 5\n",
    "check_points = Utils.get_check_points()\n",
    "symbols = Utils.get_running_symbols()\n",
    "\n",
    "date = time.strftime('%Y%m%d')\n",
    "\n",
    "data = DailyData(date=date, symbols=symbols, check_points=check_points, create=True)\n",
    "\n",
    "await data.prepare(symbols, check_points)\n",
    "\n",
    "Utils.rd.set(f'{date}_data_ready', 'true')\n",
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await asyncio.sleep(int(time.mktime(time.strptime(f'{time.strftime(\"%Y-%m-%d\")} 15:03:00', '%Y-%m-%d %H:%M:%S'))) - time.time()) \n",
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close_sharedmemory()\n",
    "data.unlink_sharedmemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.update_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_interval = 5\n",
    "check_points = Utils.get_check_points()\n",
    "symbols = Utils.get_running_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = time.strftime('%Y%m%d')\n",
    "# date = '20210219'\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DailyData(date=date, symbols=symbols, check_points=check_points, create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await data.prepare(symbols, check_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "await asyncio.sleep(data.active_time_blocks[-1][-1][1]+15-time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DailyData.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_snapshot(1611817195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_securities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DailyData.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_securities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = data.get_snapshot('11:15:30')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.loc['689009', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.check_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.check_points[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.check_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [ time.strftime('%H:%M:%S', time.localtime(cp)) for cp in data.check_points ].index('09:30:30')\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lapse = data.get_time_lapse(index)\n",
    "time_lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma5pm_anchor_idx = data.get_ma5pm_anchor_idx(index)\n",
    "ma5pm_anchor_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = data.get_snapshot('09:25:10')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, ck in enumerate(data.check_points):\n",
    "    time_lapse = data.get_time_lapse(_)\n",
    "    ma5pm_anchor_idx = data.get_ma5pm_anchor_idx(_)\n",
    "    ma5pm_anchor = data.check_points[ma5pm_anchor_idx]\n",
    "    ma5pm_anchor_str = time.strftime('%H:%M:%S', time.localtime(ma5pm_anchor))\n",
    "    ck_str = time.strftime('%H:%M:%S', time.localtime(ck))\n",
    "    print(str(_).rjust(4, ' '), ck, ck_str, ' - ', time_lapse, ma5pm_anchor_idx, ma5pm_anchor,ma5pm_anchor_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
