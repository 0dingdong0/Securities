{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import math\n",
    "import redis\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from multiprocessing.sharedctypes import RawArray\n",
    "from multiprocessing.shared_memory import SharedMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "os.chdir(Path(os.getcwd()).parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.quotation import Quotation\n",
    "from libs.utils import Utils\n",
    "from libs.tdx import TDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DailyData:\n",
    "\n",
    "    rd = redis.Redis(host='127.0.0.1', port=6379, db=8)\n",
    "\n",
    "    basics_columns = ['zt_price', 'dt_price', 'ma5vpm',\n",
    "                      'mcap', 'sum4', 'sum9', 'sum19', 'sum29', 'sum59']\n",
    "    snapshots_columns = ['open', 'close', 'now', 'high',\n",
    "                         'low', 'turnover', 'volume', 'bid1', 'bid1_volume']\n",
    "    statistic_columns = ['zhangfu', 'junjia', 'liangbi', 'zhangsu',\n",
    "                         'tingban', 'sum5', 'sum10', 'sum20', 'sum30', 'sum60']\n",
    "\n",
    "    # date: %Y%m%d\n",
    "    def __init__(self, date=None, symbols=[], check_points=[], create=False):\n",
    "\n",
    "        if date is None:\n",
    "            self.date = time.strftime('%Y%m%d')\n",
    "        else:\n",
    "            self.date = date\n",
    "\n",
    "        self.hdf5_file = os.path.join(\n",
    "            os.getcwd(), 'storage', f'{self.date}.hdf5')\n",
    "\n",
    "        if create:\n",
    "            self.rd.set(f'hq_{self.date}_symbols_length', len(symbols))\n",
    "            self.rd.set(f'hq_{self.date}_check_points_length',\n",
    "                        len(check_points))\n",
    "\n",
    "            self.shm_symbols = SharedMemory(\n",
    "                name=f'${self.date}_symbols', create=True, size=len(symbols)*np.dtype('<U6').itemsize)\n",
    "            self.shm_names = SharedMemory(name=f'${self.date}_names', create=True, size=len(\n",
    "                symbols)*np.dtype('<U4').itemsize)\n",
    "            self.shm_check_points = SharedMemory(\n",
    "                name=f'${self.date}_check_points', create=True, size=len(check_points)*np.dtype('<u4').itemsize)\n",
    "            self.shm_basics = SharedMemory(name=f'${self.date}_basics', create=True, size=len(\n",
    "                check_points)*len(symbols)*len(self.basics_columns)*np.dtype('<f8').itemsize)\n",
    "            self.shm_snapshots = SharedMemory(name=f'${self.date}_snapshots', create=True, size=len(\n",
    "                check_points)*len(symbols)*len(self.snapshots_columns)*np.dtype('<f8').itemsize)\n",
    "            self.shm_statistic = SharedMemory(name=f'${self.date}_statistic', create=True, size=len(\n",
    "                check_points)*len(symbols)*len(self.statistic_columns)*np.dtype('<f8').itemsize)\n",
    "\n",
    "            self.symbols = np.ndarray(\n",
    "                (len(symbols),), dtype='<U6', buffer=self.shm_symbols.buf)\n",
    "            self.names = np.ndarray(\n",
    "                (len(symbols),), dtype='<U4', buffer=self.shm_names.buf)\n",
    "            self.check_points = np.ndarray(\n",
    "                (len(check_points),),\n",
    "                dtype='<u4',\n",
    "                buffer=self.shm_check_points.buf\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.shm_symbols = SharedMemory(name=f'${self.date}_symbols')\n",
    "            self.shm_names = SharedMemory(name=f'${self.date}_names')\n",
    "            self.shm_check_points = SharedMemory(\n",
    "                name=f'${self.date}_check_points')\n",
    "            self.shm_basics = SharedMemory(name=f'${self.date}_basics')\n",
    "            self.shm_snapshots = SharedMemory(name=f'${self.date}_snapshots')\n",
    "            self.shm_statistic = SharedMemory(name=f'${self.date}_statistic')\n",
    "\n",
    "            symbols_length = int(self.rd.get(f'hq_{self.date}_symbols_length'))\n",
    "            check_points_length = int(self.rd.get(\n",
    "                f'hq_{self.date}_check_points_length'))\n",
    "\n",
    "            self.symbols = np.ndarray(\n",
    "                (symbols_length,), dtype='<U6', buffer=self.shm_symbols.buf)\n",
    "            self.names = np.ndarray(\n",
    "                (symbols_length,), dtype='<U4', buffer=self.shm_names.buf)\n",
    "            self.check_points = np.ndarray(\n",
    "                (check_points_length,),\n",
    "                dtype='<u4',\n",
    "                buffer=self.shm_check_points.buf\n",
    "            )\n",
    "\n",
    "            self.post_init()\n",
    "\n",
    "        self.basics = np.ndarray(\n",
    "            (len(self.symbols), len(self.basics_columns)),\n",
    "            dtype='<f8',\n",
    "            buffer=self.shm_basics.buf\n",
    "        )\n",
    "        self.snapshots = np.ndarray(\n",
    "            (len(self.check_points), len(self.symbols), len(self.snapshots_columns)),\n",
    "            dtype='<f8',\n",
    "            buffer=self.shm_snapshots.buf\n",
    "        )\n",
    "        self.statistic = np.ndarray(\n",
    "            (len(self.check_points), len(self.symbols), len(self.statistic_columns)),\n",
    "            dtype='<f8',\n",
    "            buffer=self.shm_statistic.buf\n",
    "        )\n",
    "\n",
    "    async def prepare(self, symbols, check_points):\n",
    "        q = Quotation(symbols)\n",
    "        snapshot = await q.snapshot()\n",
    "\n",
    "        self.symbols[:] = symbols[:]\n",
    "        self.names[:] = [snapshot[symbol]['name'] for symbol in symbols][:]\n",
    "        self.check_points[:] = check_points[:]\n",
    "\n",
    "        self.basics.fill(np.nan)\n",
    "        self.snapshots.fill(np.nan)\n",
    "        self.statistic.fill(np.nan)\n",
    "\n",
    "        market_values = await q.get_market_values()\n",
    "\n",
    "        await q.exit()\n",
    "\n",
    "        tdx = TDX()\n",
    "        # assert tdx.is_local_tdx_data_outdated() is not True\n",
    "        klines = tdx.kline(symbols)\n",
    "\n",
    "        for _, symbol in enumerate(symbols):\n",
    "            self.basics[_, 0] = market_values[symbol]['zt_price']\n",
    "            self.basics[_, 1] = market_values[symbol]['dt_price']\n",
    "            self.basics[_, 3] = market_values[symbol]['mcap']\n",
    "\n",
    "            if symbol not in klines:\n",
    "                continue\n",
    "\n",
    "            kline = klines[symbol]\n",
    "            self.basics[_, 2] = kline.iloc[0 -\n",
    "                                           min(5, len(kline)):]['volume'].sum()/1200\n",
    "            self.basics[_, 4] = kline.iloc[-4:]['close'].sum() if len(kline) >= 4 else np.nan\n",
    "            self.basics[_, 5] = kline.iloc[-9:]['close'].sum() if len(kline) >= 9 else np.nan\n",
    "            self.basics[_, 6] = kline.iloc[-19:]['close'].sum() if len(kline) >= 19 else np.nan\n",
    "            self.basics[_, 7] = kline.iloc[-29:]['close'].sum() if len(kline) >= 29 else np.nan\n",
    "            self.basics[_, 8] = kline.iloc[-59:]['close'].sum() if len(kline) >= 59 else np.nan\n",
    "\n",
    "        # await q.exit()\n",
    "        self.post_init()\n",
    "\n",
    "    def post_init(self):\n",
    "        self.active_time_blocks = []\n",
    "        self.check_interval = self.check_points[2] - self.check_points[1]\n",
    "        start_time_0_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 09:15:00'\n",
    "        start_time_1_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 09:30:00'\n",
    "        start_time_2_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 13:00:00'\n",
    "        end_time_0_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 09:25:00'\n",
    "        end_time_1_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 11:30:00'\n",
    "        end_time_2_str = f'{time.strftime(\"%Y-%m-%d\", time.localtime(self.check_points[0]))} 15:00:00'\n",
    "        start_time_0 = int(time.mktime(time.strptime(\n",
    "            start_time_0_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        start_time_1 = int(time.mktime(time.strptime(\n",
    "            start_time_1_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        start_time_2 = int(time.mktime(time.strptime(\n",
    "            start_time_2_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        end_time_0 = int(time.mktime(time.strptime(\n",
    "            end_time_0_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        end_time_1 = int(time.mktime(time.strptime(\n",
    "            end_time_1_str, '%Y-%m-%d %H:%M:%S')))\n",
    "        end_time_2 = int(time.mktime(time.strptime(\n",
    "            end_time_2_str, '%Y-%m-%d %H:%M:%S')))\n",
    "\n",
    "        if start_time_0 >= self.check_points[0]:\n",
    "            start_time_idx_0 = np.where(\n",
    "                self.check_points == start_time_0)[0][0]\n",
    "            end_time_idx_0 = np.where(self.check_points == end_time_0)[0][0]\n",
    "\n",
    "            self.active_time_blocks.append(\n",
    "                (\n",
    "                    (start_time_idx_0, start_time_0, start_time_0_str),\n",
    "                    (end_time_idx_0, end_time_0, end_time_0_str)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        start_time_idx_1 = np.where(self.check_points == start_time_1)[0][0]\n",
    "        end_time_idx_1 = np.where(self.check_points == end_time_1)[0][0]\n",
    "        self.active_time_blocks.append(\n",
    "            (\n",
    "                (start_time_idx_1, start_time_1, start_time_1_str),\n",
    "                (end_time_idx_1, end_time_1, end_time_1_str)\n",
    "            )\n",
    "        )\n",
    "        start_time_idx_2 = np.where(self.check_points == start_time_2)[0][0]\n",
    "        end_time_idx_2 = np.where(self.check_points == end_time_2)[0][0]\n",
    "        self.active_time_blocks.append(\n",
    "            (\n",
    "                (start_time_idx_2, start_time_2, start_time_2_str),\n",
    "                (end_time_idx_2, end_time_2, end_time_2_str)\n",
    "            )\n",
    "        )\n",
    "        # self.rd.set(f'{self.date}_data_ready', 'true')\n",
    "\n",
    "    def get_securities(self):\n",
    "        return pd.DataFrame({\n",
    "            \"symbol\": self.symbols,\n",
    "            \"name\": self.names,\n",
    "            \"zt_price\": self.basics[:, 0],\n",
    "            \"dt_price\": self.basics[:, 1],\n",
    "            \"ma5vpm\": self.basics[:, 2],\n",
    "            \"mcap\": self.basics[:, 3],\n",
    "            \"sum4\": self.basics[:, 4],\n",
    "            \"sum9\": self.basics[:, 5],\n",
    "            \"sum19\": self.basics[:, 6],\n",
    "            \"sum29\": self.basics[:, 7],\n",
    "            \"sum59\": self.basics[:, 8]\n",
    "        }).set_index('symbol')\n",
    "\n",
    "    # check_point: timestamp or %H:%M:%S\n",
    "\n",
    "    def get_snapshot(self, check_point):\n",
    "        if type(check_point) == int and check_point <= 100000:\n",
    "            index = check_point\n",
    "        elif type(check_point) == float or type(check_point) == int:\n",
    "            index = np.where(self.check_points == check_point)[0][0]\n",
    "        elif type(check_point) == str:\n",
    "            index = [time.strftime('%H:%M:%S', time.localtime(cp))\n",
    "                     for cp in self.check_points].index(check_point)\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"datetime\": [check_point if type(check_point) == str else time.strftime('%H:%M:%S', time.localtime(check_point)) for _ in range(len(self.symbols))],\n",
    "            \"timestamp\": [self.check_points[index] if type(check_point) == str else check_point for _ in range(len(self.symbols))],\n",
    "            \"symbol\": self.symbols,\n",
    "            \"name\": self.names,\n",
    "            \"open\": self.snapshots[index, :, 0],\n",
    "            \"close\": self.snapshots[index, :, 1],\n",
    "            \"now\": self.snapshots[index, :, 2],\n",
    "            \"high\": self.snapshots[index, :, 3],\n",
    "            \"low\": self.snapshots[index, :, 4],\n",
    "            \"turnover\": self.snapshots[index, :, 5],\n",
    "            \"volume\": self.snapshots[index, :, 6],\n",
    "            \"bid1\": self.snapshots[index, :, 7],\n",
    "            \"bid1_volume\": self.snapshots[index, :, 8],\n",
    "            \"zhangfu\": self.statistic[index, :, 0],\n",
    "            \"junjia\": self.statistic[index, :, 1],\n",
    "            \"liangbi\": self.statistic[index, :, 2],\n",
    "            \"zhangsu\": self.statistic[index, :, 3],\n",
    "            \"tingban\": self.statistic[index, :, 4],\n",
    "            \"ma5\": self.statistic[index, :, 5]\n",
    "        }).set_index('symbol')\n",
    "\n",
    "    # dt: %Y%m%d\n",
    "    def save(self, gzip_level=4):\n",
    "        folder = os.path.join(os.getcwd(), 'storage')\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "#         file = os.path.join(folder, f'{self.date}.hdf5')\n",
    "\n",
    "        if os.path.exists(self.hdf5_file):\n",
    "            print('文件 [', self.hdf5_file, '] 已经存在，将被删除 ... ... ', end='')\n",
    "            os.remove(self.hdf5_file)\n",
    "            print('已被删除')\n",
    "\n",
    "        symbols = np.char.encode(self.symbols, encoding='utf-8')\n",
    "        names = np.char.encode(self.names, encoding='utf-8')\n",
    "        with h5py.File(self.hdf5_file, \"a\") as f:\n",
    "            f.create_dataset(u\"symbols\", data=symbols,\n",
    "                             compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"names\", data=names,\n",
    "                             compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"check_points\", data=self.check_points,\n",
    "                             compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"basics\", data=self.basics,\n",
    "                             compression=\"gzip\", compression_opts=gzip_level)\n",
    "            f.create_dataset(u\"snapshots\", data=self.snapshots,\n",
    "                             compression=\"gzip\", compression_opts=gzip_level)\n",
    "#             f.create_dataset(u\"statistic\", data=self.statistic, compression=\"gzip\", compression_opts=gzip_level)\n",
    "\n",
    "        print('行情 已经 写入文件：', self.hdf5_file)\n",
    "\n",
    "    # dt: %Y%m%d\n",
    "    @staticmethod\n",
    "    def load(dt=None):\n",
    "        date = time.strftime(\"%Y%m%d\", time.localtime()) if dt is None else dt\n",
    "        file = os.path.join(os.getcwd(), 'storage', f'{date}.hdf5')\n",
    "        assert os.path.exists(file), 'file['+file+'] does not exists!'\n",
    "\n",
    "        with h5py.File(file, \"a\") as f:\n",
    "            symbols = np.char.decode(f[u'symbols'], 'utf-8')\n",
    "            check_points = f[u'check_points'][:]\n",
    "\n",
    "            data = DailyData(date=date, symbols=symbols,\n",
    "                             check_points=check_points, create=True)\n",
    "            data.symbols[:] = symbols[:]\n",
    "            data.names[:] = np.char.decode(f[u'names'], 'utf-8')\n",
    "            data.check_points[:] = check_points\n",
    "            data.basics[:, :] = f[u'basics'][:, :]\n",
    "            data.snapshots[:, :, :] = f[u'snapshots'][:, :, :]\n",
    "#             data.statistic[:,:,:] = f[u'statistic'][:,:,:]\n",
    "\n",
    "        data.post_init()\n",
    "        return data\n",
    "\n",
    "    def get_ma5pm_anchor_idx(self, idx):\n",
    "        \n",
    "        if self.check_interval == 60:\n",
    "            if idx<=121:\n",
    "                return max(0, idx-5)\n",
    "            elif idx<=126:\n",
    "                return idx-6\n",
    "            else:\n",
    "                return idx-5\n",
    "        else:\n",
    "            # st = time.time()\n",
    "\n",
    "            ck = self.check_points[idx]\n",
    "\n",
    "            if ck <= self.active_time_blocks[0][0][1]+300:\n",
    "                ma5pm_anchor_idx = self.active_time_blocks[0][0][0] - 1\n",
    "\n",
    "            elif self.active_time_blocks[0][1][1] < ck < self.active_time_blocks[1][0][1]:\n",
    "                ma5pm_anchor_idx = int(\n",
    "                    self.active_time_blocks[0][1][0] - 300/self.check_interval)\n",
    "\n",
    "            elif self.active_time_blocks[1][0][1] <= ck <= self.active_time_blocks[1][0][1]+300:\n",
    "                ma5pm_anchor_idx = self.active_time_blocks[1][0][0] - 1\n",
    "\n",
    "            elif self.active_time_blocks[1][1][1] < ck < self.active_time_blocks[2][0][1]:\n",
    "                ma5pm_anchor_idx = int(\n",
    "                    self.active_time_blocks[1][1][0] - 300/self.check_interval)\n",
    "\n",
    "            elif self.active_time_blocks[2][0][1] <= ck <= self.active_time_blocks[2][0][1]+300:\n",
    "                result = math.ceil(self.check_points[idx]/60)*60-300\n",
    "                offset = int((result-self.check_points[idx])/self.check_interval)\n",
    "\n",
    "                ma5pm_anchor_idx = int(\n",
    "                    max(idx+offset-2, self.active_time_blocks[1][1][0] - 240/self.check_interval))\n",
    "\n",
    "                if ma5pm_anchor_idx == self.active_time_blocks[1][1][0]:\n",
    "                    ma5pm_anchor_idx += 1\n",
    "\n",
    "            elif self.active_time_blocks[2][1][1] < ck:\n",
    "                ma5pm_anchor_idx = int(\n",
    "                    self.active_time_blocks[2][1][0]-300/self.check_interval)\n",
    "\n",
    "            else:\n",
    "                result = math.ceil(self.check_points[idx]/60)*60-300\n",
    "                offset = int((result-self.check_points[idx])/self.check_interval)\n",
    "\n",
    "                ma5pm_anchor_idx = idx+offset\n",
    "\n",
    "            # et = time.time()\n",
    "\n",
    "            # print(\n",
    "            #     idx, ' : ', ma5pm_anchor_idx, '       ',\n",
    "            #     time.strftime(\"%H:%M:%S\", time.localtime(self.check_points[idx])),\n",
    "            #     ' ==> ',\n",
    "            #     time.strftime(\"%H:%M:%S\", time.localtime(self.check_points[ma5pm_anchor_idx])), '       ',\n",
    "            #     ck, ' : ', self.check_points[ma5pm_anchor_idx], '       ',\n",
    "            #     et-st\n",
    "            # )\n",
    "\n",
    "            return ma5pm_anchor_idx\n",
    "        \n",
    "        \n",
    "    def get_time_lapse(self, idx):\n",
    "\n",
    "        ck = self.check_points[idx]\n",
    "        diff_0000 = (ck+28800)%86400 # 8*3600=28800, 24*3600=86400\n",
    "\n",
    "        if diff_0000 <= 33300: # 09:15:00, 9*3600+15*60=33300\n",
    "            return 1\n",
    "        elif diff_0000 <= 33900: # 09:25:00, 9*3600+25*60=33900\n",
    "            return math.ceil((diff_0000-33300)/60)\n",
    "        elif diff_0000 < 34200: # 09:30:00, 9*3600+30*60=34200\n",
    "            return 10\n",
    "        elif diff_0000 <= 41400: # 11:30:00, 11*3600+30*60=41400\n",
    "            return max(1,math.ceil((diff_0000-34200)/60))\n",
    "        elif diff_0000 < 46800: # 13:00:00, 13*3600=46800\n",
    "            return 120\n",
    "        elif diff_0000 <= 54000: # 15:00:00, 15*3600=54000\n",
    "            return 120+max(1,math.ceil((diff_0000-46800)/60))\n",
    "        else:\n",
    "            return 240\n",
    "        \n",
    "\n",
    "    def close_sharedmemory(self):\n",
    "        self.shm_symbols.close()\n",
    "        self.shm_names.close()\n",
    "        self.shm_check_points.close()\n",
    "        self.shm_basics.close()\n",
    "        self.shm_snapshots.close()\n",
    "        self.shm_statistic.close()\n",
    "\n",
    "    def unlink_sharedmemory(self):\n",
    "        self.shm_symbols.unlink()\n",
    "        self.shm_names.unlink()\n",
    "        self.shm_check_points.unlink()\n",
    "        self.shm_basics.unlink()\n",
    "        self.shm_snapshots.unlink()\n",
    "        self.shm_statistic.unlink()\n",
    "\n",
    "    def incremental_save(self, idx):\n",
    "        # with h5py.File(self.hdf5_file, \"r+\") as f:\n",
    "        #     f[u'snapshots'][idx] = self.snapshots[idx]\n",
    "\n",
    "        if not hasattr(self, 'hdf5'):\n",
    "            if not os.path.exists(self.hdf5_file):\n",
    "                return 'file['+self.hdf5_file+'] does not exists!'\n",
    "            self.hdf5 = h5py.File(self.hdf5_file, 'r+')\n",
    "\n",
    "        self.hdf5[u'snapshots'][idx] = self.snapshots[idx]\n",
    "\n",
    "        if (idx+1) == len(self.check_points):\n",
    "            self.hdf5.close()\n",
    "        else:\n",
    "            self.hdf5.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.update_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_interval = 5\n",
    "check_points = Utils.get_check_points()\n",
    "symbols = Utils.get_running_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DailyData(symbols, check_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await data.prepare(symbols, check_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DailyData.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_securities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.start_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'300933' in data.symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_snapshot('09:16:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_snapshot(1611018960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.statistic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DailyData.load(dt='20210812')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################   测试 get_ma5pm_anchor_idx, get_time_lapse  ####################################\n",
    "result1 = []\n",
    "for _, ck in enumerate(data.check_points):\n",
    "    print(_, ' | ', time.strftime(\"%H:%M:%S\", time.localtime(ck)),\n",
    "          ' -> ',\n",
    "          time.strftime(\"%H:%M:%S\", time.localtime(data.check_points[data.get_ma5pm_anchor_idx(_)])), ' | ',\n",
    "          data.get_time_lapse(_)\n",
    "         )\n",
    "    result1.append((_,time.strftime(\"%H:%M:%S\", time.localtime(ck)), time.strftime(\"%H:%M:%S\", time.localtime(data.check_points[data.get_ma5pm_anchor_idx(_)])), data.get_time_lapse(_)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(3007):\n",
    "    if all([ result[_][i] == result1[_][i] for i in range(4)]):\n",
    "        continue\n",
    "    print(result[_])\n",
    "    print(result1[_])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "data.get_ma5pm_anchor_idx(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "data.get_time_lapse(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ rebuld from minite data ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils import Utils\n",
    "Utils.update_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Quotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await q.real(['002717'])\n",
    "result = await q.min_data(['002717'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.check_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = time.strftime('%Y-%m-%d')\n",
    "\n",
    "check_points = []\n",
    "for start_time in ['09:30:00', '13:00:00']:\n",
    "    timestamp = int(time.mktime(time.strptime(f'{today} {start_time}', '%Y-%m-%d %H:%M:%S')))\n",
    "    for i in range(121):\n",
    "        check_points.append(timestamp+i*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ck in check_points:\n",
    "#     print(ck, time.strftime(\"%H:%M:%S\", time.localtime(ck)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = Utils.get_running_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = time.strftime('%Y%m%d')\n",
    "dd = DailyData(date=today, symbols=symbols,\n",
    "                 check_points=check_points, create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "await dd.prepare(symbols, check_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################   测试 get_ma5pm_anchor_idx, get_time_lapse  ####################################\n",
    "for _, ck in enumerate(dd.check_points):\n",
    "    print(_, ' | ',\n",
    "          time.strftime(\"%H:%M:%S\", time.localtime(ck)),' -> ',\n",
    "          time.strftime(\"%H:%M:%S\", time.localtime(dd.check_points[dd.get_ma5pm_anchor_idx(_)])), ' | ',\n",
    "          dd.get_time_lapse(_)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.active_time_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method():\n",
    "    pass\n",
    "obj.method = types.MethodType(method, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await q.min_data(dd.symbols.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.symbols.tolist().index('002717')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now\n",
    "dd.snapshots[:,1164,2] = [ x[1] for x in results['002717']['data'] ]\n",
    "# turnover\n",
    "dd.snapshots[:,1164,5] = [ x[2] for x in results['002717']['data'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data.close_sharedmemory()\n",
    "    data.unlink_sharedmemory()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    dd.close_sharedmemory()\n",
    "    dd.unlink_sharedmemory()\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
